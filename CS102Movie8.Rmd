---
title: "CS102Movie8"
author: "Anton Geganzo"
date: "2024-02-13"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r 1}
library(rvest)
library(httr)
library(polite)
```

```{r 2}
polite::use_manners(save_as = 'polite_scrape.R')
```

```{r 3}
URL <- 'https://www.imdb.com/title/tt0050083/reviews/_ajax?ref_=undefined&paginationKey=%s'
```

```{r 4}
scrape_page <- function(URL, Page_key) {
  session <- bow(sprintf(URL, Page_key), user_agent = "Educational")
  USER <- scrape(session) %>% html_nodes('span.display-name-link') %>% html_text()
  Dates <- scrape(session) %>% html_nodes('span.review-date') %>% html_text()
  Contents <- scrape(session) %>% html_nodes('div.text.show-more__control') %>% html_text()
  Ratings <- scrape(session) %>% html_nodes('span.rating-other-user-rating') %>% html_text()
  
  Page_key <- scrape(session) %>% html_nodes("div.load-more-data") %>% html_attr("data-key")
  
  return(list(USER = USER, Dates = Dates, Contents = Contents, Ratings = Ratings, Page_key = Page_key))
}
```

```{r 5}
USER <- character(0)
Dates <- character(0)
Contents <- character(0)
Ratings <- character(0)
Page_key <- ""
```

```{r 6}
reviews_to_scrape <- 300
per_page <- 25
pages_to_scrape <- ceiling(reviews_to_scrape / per_page)
```

```{r 7}
for (page in 1:pages_to_scrape) {
  scraped_data <- scrape_page(URL, Page_key)
  
  USER <- c(USER, scraped_data$USER)
  Dates <- c(Dates, scraped_data$Dates)
  Contents <- c(Contents, scraped_data$Contents)
  Ratings <- c(Ratings, scraped_data$Ratings)
  
  Page_key <- scraped_data$Page_key
  
  if (length(USER) >= reviews_to_scrape) {
    break
  }
}
```

```{r 8}
DataFrame <- data.frame(
  USER = USER[1:300],
  Reviewer_Date = Dates[1:300],
  Reviewer_Content = Contents[1:300],
  Rating = Ratings[1:300]
)
```

```{r 9}
write.csv(DataFrame, file = "CS102Movie8.csv", row.names = FALSE)
```

```{r 10}
print(DataFrame)
```
